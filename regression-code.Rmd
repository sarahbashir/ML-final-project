---
title: "Regression code"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, cache=TRUE, message=FALSE, warning=FALSE,
                      fig.width=7, fig.height=3, fig.align = "center")
options(digits=3)

library(e1071)
library(tidyverse)
library(DAAG)
library(caret)
library(ggplot2)
library(sandwich)
library(msm)

```

Logistic Refression:

```{r}

war_Data <- readr::read_csv("weather.csv")

#head(war_Data)

#using scatter plot to visualize relationship between minTemp and maxTemp

scatter.smooth(x=war_Data$MinTemp, y=war_Data$MaxTemp, main="MinTemp ~ MaxTemp", col = '#CCCCCC')

#ggplot2.scatterplot(data=war_data, xName = 'war_Data$MinTemp', yName = 'war_Data$MaxTemp', addRegLine=TRUE, regLineColor = ' blue', smoothingMethod = 'loess')

```


```{r}
#checking for outliers using a box plot

par(mfrow=c(1, 2))  # divide graph area in 2 columns

boxplot(war_Data$MinTemp, main="MinTemp", sub=paste("Outlier rows: ", boxplot.stats(cars$speed)$out))  # box plot for 'MinTemp'

boxplot(war_Data$MaxTemp, main="MaxTemp", sub=paste("Outlier rows: ", boxplot.stats(cars$dist)$out))  # box plot for 'MaxTemp'

```

```{r}

#checking if response variable is close to normal using density plot

par(mfrow=c(1, 2))  # divide graph area in 2 columns

plot(density(war_Data$MinTemp), main="Density Plot: MinTemp", ylab="Frequency", sub=paste("Skewness:", round(e1071::skewness(war_Data$MinTemp), 2)))  # density plot for 'MinTemp'

polygon(density(war_Data$MinTemp), col="red")

plot(density(war_Data$MaxTemp), main="Density Plot: MaxTemp", ylab="Frequency", sub=paste("Skewness:", round(e1071::skewness(war_Data$MaxTemp), 2)))  # density plot for 'MaxTemp'

polygon(density(war_Data$MaxTemp), col="red")

```


```{r}
#correlation

cor(war_Data$MinTemp, war_Data$MaxTemp)

```
We see that there's a strong positive relationship between MinTemp and MaxTemp (close to 1).

```{r}

#linear regression model

linearModel <- lm(MaxTemp ~ MinTemp, data=war_Data)
print(linearModel)

#model Summary
modelSummary<-summary(linearModel)

#model coeffecients
modelCoefficients <- modelSummary$coefficients

#beta estimate
beta_Estimate <- modelCoefficients["MinTemp", "Estimate"]

#standard error 
std_Error <- modelCoefficients["MinTemp", "Std. Error"]

#t statistics
t_Value <- beta_Estimate/std_Error

#p value
p_Value <- 2*pt(-abs(t_Value), df = nrow(war_Data)-ncol(war_Data))


#f stat
f_Stat <- linearModel$fstatistic[1]

#parameters for model p-val
f <- summary(linearModel)$f_Stat 


#p_Value_Model <- pf(f[1], f[2], f[3], lower=FALSE)

```

```{r}

#create training and test data 
set.seed(47)
trainingIndex <- sample(1:nrow(war_Data), 0.8*nrow(war_Data)) #row indices for training
trainData <- war_Data[trainingIndex, ] #training data
testData <- war_Data[-trainingIndex, ] #test data

#build model on training data
linMod <- lm(MaxTemp ~ MinTemp, data=trainData)
prediction <- predict(linMod, testData) #predict temp

actual<- testData$MaxTemp

#out of sample RMSE
sqrt(mean(prediction-actual)^2)

#fit a model to the full data set
linMod2 <- lm(MaxTemp ~ MinTemp, data=war_Data)

#predict in-sample
prediction2 <- predict(linMod2, war_Data)

#get RMSE
actual2 <- war_Data$MaxTemp
sqrt(mean(prediction2-actual2)^2)


summary(linMod)

```
We see model and predictor p value are less than 0.05 so the model is statistically significant. R squared and adjusted R squared are comparitive to the orginial model built on the full data.

Now calculate prediction accuracy and error rates:

Look at correlation between actual and predicted values. 

```{r}

actual_pred <- data.frame(cbind(actual=testData$MaxTemp, predict=prediction)) #make precited and actual data frame
correlation_Acc <- cor(actual_pred)
correlation_Acc #87.9%
head(actual_pred)

DMwR::regr.eval(actual_pred$actual,actual_pred$predict)




```


Poisson Regression: 

Looking at relationship between temperature and number of bikes.
```{r}

bikes_Data <- readr::read_csv("bikes.csv")

bikes_Data<-as.data.frame(bikes_Data)

head(bikes_Data)


```
Will use mean temperature (high - low/2) to predict volume of bikes per day. First find class of each variable and if there are any missing variables. Then will plot to see the relationship between number of bikes and mean temperature.

```{r}
print("Is there any missing value?")
sum(is.na(bikes_Data[,c('High Temp (°F)', 'Low Temp (°F)','Total')]))
print("Are these variable numerics?")
is.numeric(bikes_Data[,'High Temp (°F)'])
is.numeric(bikes_Data[,'Low Temp (°F)'])
is.numeric(bikes_Data[,'Total'])
print("Are integers?")
all.equal(bikes_Data[,'Total'], as.integer(bikes_Data[,'Total'])) == T

```
```{r}

#create "Mean temperature".
bikes_Data$Mean_Temperature<-(bikes_Data[,'High Temp (°F)']+bikes_Data[,'Low Temp (°F)'])/2
#Poisson plot
ggplot(bikes_Data, aes(x = Mean_Temperature, y = Total)) +
    geom_point() + 
    geom_smooth(method = "glm", #plot poisson regression
    method.args = list(family = "poisson"))



```
```{r}

bikesModel <- glm(bikes_Data$Mean_Temperature ~ bikes_Data$Total, poisson)

cov.model <- vcovHC(bikesModel, type = "HC0")
std.error <- sqrt(diag(cov.model))
r.est <- cbind(Estimate = coef(bikesModel), "Robust SE" = std.error, "Pr(>|z|)" = 2 * pnorm(abs(coef(bikesModel)/std.error), lower.tail = FALSE),
LL = coef(bikesModel) - 1.96 * std.error, 
UL = coef(bikesModel) + 1.96 * std.error)

r.est

pchisq(bikesModel$deviance, df=bikesModel$df.residual, lower.tail = FALSE)

summary(bikesModel)

```
Median is 0, deviance residuals are normally distributed. Coeffeicient for Total is close to 0. Residual deviance provides a goodness of fit test for the overall model. Residual deviance is the difference beween the deviance of the current model and the max deviance of the ideal model where the predicted values are the same as those observed. If the residual difference is small enough, the goodness of fit test will not be significant, indicating that the model fits the data. We conclude that the model fits well because the goodness of fit chi-squared test is not statistically significant. If it was, it would indicate that the data did not fit the model well.

The positive coefficient for Mean_Temperature means that as Mean Temeperature increases, the total number of bikes also increases.

This coeffecient is highly significant (p < 2e-16).

Residual deviance is slightly higher than the degrees of freedom, which means we have slight over dispersion. Means that there is extra variance not accounted for by the model.

Aim to refit the model using quasi Poisson errors (see if this will help). Over dispersion is an issue if the residual variance is larger than the conditional mean. The quasi-poisson model will fit an extra dispersion paramater to account for the extra variance.

```{r}

quasi_Model <- bikesModel <- glm(bikes_Data$Mean_Temperature ~ bikes_Data$Total, quasipoisson)

pchisq(quasi_Model$deviance, df=quasi_Model$df.residual, lower.tail = FALSE)


summary(quasi_Model)


```
We see the dispersion paramater is slightly higher. This paramater tells us how many times larger the variance is than the mean. In this case, the difference between the residual and null deviance is the same as the original model and the dispersion paramater is higher, so the original Poisson model was better.

```{r}

set.seed(35)

inTrain <- caret::createDataPartition(y=bikes_Data$Total, p=.8, list=FALSE)
BR.train <- bikes_Data[inTrain,]
BR.test <- bikes_Data[-inTrain,]


#build model on training data
#in sample accuracy
#need to convert log odds to a probability
poisMod <- glm(Mean_Temperature ~ Total, data = bikes_Data, family = poisson)
poisPrediction <- predict(poisMod, bikes_Data) #predict temp
poisPred <- gtools::inv.logit(poisPrediction)

predictionProbs <- data.frame(prob.poisson = poisPred)

mean(predictionProbs[,1])

#out of sample performance (on test data)


poisModOOS <- glm(Mean_Temperature ~ Total, data = BR.train, family = poisson)
poisPredictionOOS <- predict(poisModOOS, BR.test) #predict temp
poisPredOOS <- gtools::inv.logit(poisPredictionOOS)

predictionProbsOOS <- data.frame(prob.poissonOOS = poisPredOOS)

mean(predictionProbsOOS[,1])







pchisq(bikesModel$deviance, df=bikesModel$df.residual, lower.tail = FALSE)





```
P-value of 0.193 suggests that a residual deviance as large or larger than what we observed under the model in bikesModel is highly likely. Suggests that the model is of adequate fit, since the chi-squared test was not statistically significant.

Looking at Precipitation: 

```{r}

#Look at precipatation
bikes_Data[,"Precipitation"]<-as.numeric(bikes_Data[,"Precipitation"]) #get rid of n/a's in dataset
ggplot(bikes_Data, aes(x = Precipitation, y = Total)) + 
    geom_point() + 
    geom_smooth(method = "glm", #plot regression
    method.args = list(family = "poisson")) 


```
We see that a higher mean temperature means more bikes while a higher level of preciptation means a lower amount of bikes.











