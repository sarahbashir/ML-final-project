---
title: "Regression code"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, cache=TRUE, message=FALSE, warning=FALSE,
                      fig.width=7, fig.height=3, fig.align = "center")
options(digits=3)

library(e1071)
library(tidyverse)

```

Logistic Refression:

```{r}

war_Data <- readr::read_csv("weather.csv")

#head(war_Data)

#using scatter plot to visualize relationship between minTemp and maxTemp

scatter.smooth(x=war_Data$MinTemp, y=war_Data$MaxTemp, main="MinTemp ~ MaxTemp")

```


```{r}
#checking for outliers using a box plot

par(mfrow=c(1, 2))  # divide graph area in 2 columns

boxplot(war_Data$MinTemp, main="MinTemp", sub=paste("Outlier rows: ", boxplot.stats(cars$speed)$out))  # box plot for 'MinTemp'

boxplot(war_Data$MaxTemp, main="MaxTemp", sub=paste("Outlier rows: ", boxplot.stats(cars$dist)$out))  # box plot for 'MaxTemp'

```

```{r}

#checking if response variable is close to normal using density plot

par(mfrow=c(1, 2))  # divide graph area in 2 columns

plot(density(war_Data$MinTemp), main="Density Plot: MinTemp", ylab="Frequency", sub=paste("Skewness:", round(e1071::skewness(war_Data$MinTemp), 2)))  # density plot for 'MinTemp'

polygon(density(war_Data$MinTemp), col="red")

plot(density(war_Data$MaxTemp), main="Density Plot: MaxTemp", ylab="Frequency", sub=paste("Skewness:", round(e1071::skewness(war_Data$MaxTemp), 2)))  # density plot for 'MaxTemp'

polygon(density(war_Data$MaxTemp), col="red")

```


```{r}
#correlation

cor(war_Data$MinTemp, war_Data$MaxTemp)

```
We see that there's a strong positive relationship between MinTemp and MaxTemp (close to 1).

```{r}

#linear regression model

linearModel <- lm(MaxTemp ~ MinTemp, data=war_Data)
print(linearModel)

#model Summary
modelSummary<-summary(linearModel)

#model coeffecients
modelCoefficients <- modelSummary$coefficients

#beta estimate
beta_Estimate <- modelCoefficients["MinTemp", "Estimate"]

#standard error 
std_Error <- modelCoefficients["MinTemp", "Std. Error"]

#t statistics
t_Value <- beta_Estimate/std_Error

#p value
p_Value <- 2*pt(-abs(t_Value), df = nrow(war_Data)-ncol(war_Data))


#f stat
f_Stat <- linearModel$fstatistic[1]

#parameters for model p-val
f <- summary(linearModel)$f_Stat 


#p_Value_Model <- pf(f[1], f[2], f[3], lower=FALSE)

```

Poisson Regression: 

Looking at relationship between temperature and number of bikes.
```{r}

bikes_Data <- readr::read_csv("bikes.csv")

bikes_Data<-as.data.frame(bikes_Data)

head(bikes_Data)


```
Will use mean temperature (high - low/2) to predict volume of bikes per dat. First find class of each variable and if there are any missing variables. Then will plot to see the relationship between number of bikes and mean temperature.

```{r}
print("Is there any missing value?")
sum(is.na(bikes_Data[,c('High Temp (°F)', 'Low Temp (°F)','Total')]))
print("Are these variable numerics?")
is.numeric(bikes_Data[,'High Temp (°F)'])
is.numeric(bikes_Data[,'Low Temp (°F)'])
is.numeric(bikes_Data[,'Total'])
print("Are integers?")
all.equal(bikes_Data[,'Total'], as.integer(bikes_Data[,'Total'])) == T

```
```{r}

#create "Mean temperature".
bikes_Data$Mean_Temperature<-(bikes_Data[,'High Temp (°F)']+bikes_Data[,'Low Temp (°F)'])/2
#Poisson plot
ggplot(bikes_Data, aes(x = Mean_Temperature, y = Total)) +
    geom_point() + 
    geom_smooth(method = "glm", #plot poisson regression
    method.args = list(family = "poisson"))



```
```{r}

bikesModel <- glm(bikes_Data$Total ~ bikes_Data$Mean_Temperature)

summary(bikesModel)

```

The positive coefficient for Mean_Temperature means that as Mean Temeprature increases, the total number of bikes also increases.

This coeffecient is highly significant (p < 2e-16).

Residual deviance is higher than the degrees of freedom, which means we have over dispersion. Means that there is extra variance not accounted for by the model.

Aim to refit the model using quasi Poisson errors. Over dispersion is an issue if the residual variance is larger than the conditional mean. The quasi-poisson model will fit an extra dispersion paramater to account for the extra variance.

```{r}

quasi_Model <- bikesModel <- glm( bikes_Data$Total ~ bikes_Data$Mean_Temperature, quasipoisson)
summary(quasi_Model)


```
Residual deviance has decreased. Dispersion paramater is much lower. This paramater tells us bow many times larger the variance is htan the mean.

Looking at Precipitation: 

```{r}

#Look at precipatation
bikes_Data[,"Precipitation"]<-as.numeric(bikes_Data[,"Precipitation"]) #get rid of n/a's in dataset
ggplot(bikes_Data, aes(x = Precipitation, y = Total)) + 
    geom_point() + 
    geom_smooth(method = "glm", #plot regression
    method.args = list(family = "poisson")) 


```
We see that a higher mean temperature means more bikes while a higher level of preciptation means a lower amount of bikes.











